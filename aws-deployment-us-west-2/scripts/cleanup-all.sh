#!/bin/bash

# AWS us-west-2 Spring Cloud Nacos é¡¹ç›®å®Œæ•´åˆ é™¤è„šæœ¬
# ç‰ˆæœ¬: 1.0

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# çŽ¯å¢ƒå˜é‡
CLUSTER_NAME=nacos-microservices
NAMESPACE=nacos-microservices
ECR_REGISTRY=$(aws sts get-caller-identity --query Account --output text).dkr.ecr.us-west-2.amazonaws.com
ECR_REPOSITORY_PREFIX=nacos-demo

# ç¡®è®¤åˆ é™¤
confirm_deletion() {
    log_warning "âš ï¸  å³å°†åˆ é™¤ä»¥ä¸‹AWSèµ„æºï¼š"
    echo "   - EKSé›†ç¾¤: $CLUSTER_NAME"
    echo "   - ECRä»“åº“: nacos-demo/*"
    echo "   - IAMè§’è‰²å’Œç­–ç•¥"
    echo "   - è´Ÿè½½å‡è¡¡å™¨å’Œç›¸å…³ç½‘ç»œèµ„æº"
    echo ""
    log_warning "æ­¤æ“ä½œä¸å¯é€†è½¬ï¼"
    echo ""
    
    read -p "ç¡®è®¤åˆ é™¤æ‰€æœ‰èµ„æºï¼Ÿ(è¾“å…¥ 'DELETE' ç¡®è®¤): " confirmation
    
    if [ "$confirmation" != "DELETE" ]; then
        log_info "åˆ é™¤æ“ä½œå·²å–æ¶ˆ"
        exit 0
    fi
    
    log_info "å¼€å§‹åˆ é™¤èµ„æº..."
}

# åˆ é™¤Kubernetesåº”ç”¨èµ„æº
delete_kubernetes_resources() {
    log_info "åˆ é™¤Kubernetesåº”ç”¨èµ„æº..."
    
    # æ£€æŸ¥é›†ç¾¤æ˜¯å¦å­˜åœ¨
    if ! kubectl config current-context | grep -q $CLUSTER_NAME 2>/dev/null; then
        log_warning "kubectlæœªé…ç½®æˆ–é›†ç¾¤ä¸å­˜åœ¨ï¼Œè·³è¿‡Kubernetesèµ„æºåˆ é™¤"
        return 0
    fi
    
    # åˆ é™¤Ingressï¼ˆè¿™ä¼šåˆ é™¤ALBï¼‰
    log_info "åˆ é™¤ALB Ingress..."
    kubectl delete ingress nacos-microservices-ingress -n $NAMESPACE --ignore-not-found=true
    
    log_info "ç­‰å¾…ALBåˆ é™¤å®Œæˆ..."
    sleep 60
    
    # åˆ é™¤æ‰€æœ‰Deployment
    log_info "åˆ é™¤æ‰€æœ‰Deployment..."
    kubectl delete deployment --all -n $NAMESPACE --ignore-not-found=true
    
    # åˆ é™¤StatefulSet
    log_info "åˆ é™¤Nacos StatefulSet..."
    kubectl delete statefulset nacos-server -n $NAMESPACE --ignore-not-found=true
    
    # åˆ é™¤æ‰€æœ‰Service
    log_info "åˆ é™¤æ‰€æœ‰Service..."
    kubectl delete service --all -n $NAMESPACE --ignore-not-found=true
    
    # åˆ é™¤ConfigMapå’ŒSecret
    log_info "åˆ é™¤ConfigMapå’ŒSecret..."
    kubectl delete configmap --all -n $NAMESPACE --ignore-not-found=true
    kubectl delete secret --all -n $NAMESPACE --ignore-not-found=true
    
    # åˆ é™¤PVC
    log_info "åˆ é™¤PVC..."
    kubectl delete pvc --all -n $NAMESPACE --ignore-not-found=true
    
    # åˆ é™¤å‘½åç©ºé—´
    log_info "åˆ é™¤å‘½åç©ºé—´..."
    kubectl delete namespace $NAMESPACE --ignore-not-found=true
    
    log_success "Kubernetesåº”ç”¨èµ„æºåˆ é™¤å®Œæˆ"
}

# åˆ é™¤AWS Load Balancer Controller
delete_alb_controller() {
    log_info "åˆ é™¤AWS Load Balancer Controller..."
    
    # åˆ é™¤Helm release
    if helm list -n kube-system | grep -q aws-load-balancer-controller; then
        helm uninstall aws-load-balancer-controller -n kube-system
        log_success "AWS Load Balancer Controller Helm releaseå·²åˆ é™¤"
    fi
    
    # åˆ é™¤ServiceAccount
    kubectl delete serviceaccount aws-load-balancer-controller -n kube-system --ignore-not-found=true
    
    log_success "AWS Load Balancer Controlleråˆ é™¤å®Œæˆ"
}

# åˆ é™¤EKSé›†ç¾¤
delete_eks_cluster() {
    log_info "åˆ é™¤EKSé›†ç¾¤..."
    
    if aws eks describe-cluster --name $CLUSTER_NAME --region us-west-2 &> /dev/null; then
        log_info "å¼€å§‹åˆ é™¤EKSé›†ç¾¤ï¼Œè¿™å¯èƒ½éœ€è¦10-15åˆ†é’Ÿ..."
        
        # ä½¿ç”¨eksctlåˆ é™¤é›†ç¾¤ï¼ˆæŽ¨èæ–¹å¼ï¼‰
        eksctl delete cluster --name $CLUSTER_NAME --region us-west-2 --wait
        
        log_success "EKSé›†ç¾¤åˆ é™¤å®Œæˆ"
    else
        log_info "EKSé›†ç¾¤ä¸å­˜åœ¨ï¼Œè·³è¿‡åˆ é™¤"
    fi
    
    # æ¸…ç†æœ¬åœ°kubeconfig
    log_info "æ¸…ç†æœ¬åœ°kubeconfig..."
    kubectl config delete-context arn:aws:eks:us-west-2:$(aws sts get-caller-identity --query Account --output text):cluster/$CLUSTER_NAME 2>/dev/null || true
    kubectl config delete-cluster arn:aws:eks:us-west-2:$(aws sts get-caller-identity --query Account --output text):cluster/$CLUSTER_NAME 2>/dev/null || true
    
    log_success "æœ¬åœ°kubeconfigæ¸…ç†å®Œæˆ"
}

# åˆ é™¤ECRä»“åº“
delete_ecr_repositories() {
    log_info "åˆ é™¤ECRä»“åº“..."
    
    local services=("gateway-service" "user-service" "order-service" "notification-service")
    
    for service in "${services[@]}"; do
        local repo_name="$ECR_REPOSITORY_PREFIX/$service"
        
        if aws ecr describe-repositories --repository-names $repo_name --region us-west-2 &> /dev/null; then
            log_info "åˆ é™¤ECRä»“åº“: $repo_name"
            
            # åˆ é™¤æ‰€æœ‰é•œåƒ
            local image_tags=$(aws ecr list-images --repository-name $repo_name --region us-west-2 --query 'imageIds[*].imageTag' --output text 2>/dev/null || echo "")
            
            if [ ! -z "$image_tags" ]; then
                aws ecr batch-delete-image \
                    --repository-name $repo_name \
                    --image-ids imageTag=$image_tags \
                    --region us-west-2 &> /dev/null || true
            fi
            
            # åˆ é™¤ä»“åº“
            aws ecr delete-repository \
                --repository-name $repo_name \
                --force \
                --region us-west-2
            
            log_success "ECRä»“åº“ $repo_name åˆ é™¤å®Œæˆ"
        else
            log_info "ECRä»“åº“ $repo_name ä¸å­˜åœ¨ï¼Œè·³è¿‡åˆ é™¤"
        fi
    done
}

# åˆ é™¤IAMè§’è‰²å’Œç­–ç•¥
delete_iam_resources() {
    log_info "åˆ é™¤IAMè§’è‰²å’Œç­–ç•¥..."
    
    # åˆ é™¤Load Balancer Controllerè§’è‰²
    if aws iam get-role --role-name AmazonEKSLoadBalancerControllerRole --region us-west-2 &> /dev/null; then
        log_info "åˆ é™¤Load Balancer Controllerè§’è‰²..."
        
        # åˆ†ç¦»ç­–ç•¥
        aws iam detach-role-policy \
            --role-name AmazonEKSLoadBalancerControllerRole \
            --policy-arn arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):policy/AWSLoadBalancerControllerIAMPolicy \
            --region us-west-2 2>/dev/null || true
        
        # åˆ é™¤è§’è‰²
        aws iam delete-role \
            --role-name AmazonEKSLoadBalancerControllerRole \
            --region us-west-2
        
        log_success "Load Balancer Controllerè§’è‰²åˆ é™¤å®Œæˆ"
    fi
    
    # åˆ é™¤EKSé›†ç¾¤æœåŠ¡è§’è‰²
    if aws iam get-role --role-name nacos-eks-cluster-role --region us-west-2 &> /dev/null; then
        log_info "åˆ é™¤EKSé›†ç¾¤æœåŠ¡è§’è‰²..."
        
        # åˆ†ç¦»ç­–ç•¥
        aws iam detach-role-policy \
            --role-name nacos-eks-cluster-role \
            --policy-arn arn:aws:iam::aws:policy/AmazonEKSClusterPolicy \
            --region us-west-2 2>/dev/null || true
        
        # åˆ é™¤è§’è‰²
        aws iam delete-role \
            --role-name nacos-eks-cluster-role \
            --region us-west-2
        
        log_success "EKSé›†ç¾¤æœåŠ¡è§’è‰²åˆ é™¤å®Œæˆ"
    fi
    
    # åˆ é™¤Load Balancer Controllerç­–ç•¥
    local policy_arn="arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):policy/AWSLoadBalancerControllerIAMPolicy"
    if aws iam get-policy --policy-arn $policy_arn --region us-west-2 &> /dev/null; then
        log_info "åˆ é™¤Load Balancer Controllerç­–ç•¥..."
        aws iam delete-policy --policy-arn $policy_arn --region us-west-2
        log_success "Load Balancer Controllerç­–ç•¥åˆ é™¤å®Œæˆ"
    fi
}

# æ¸…ç†OIDCèº«ä»½æä¾›ç¨‹åº
delete_oidc_provider() {
    log_info "æ¸…ç†OIDCèº«ä»½æä¾›ç¨‹åº..."
    
    local oidc_arn=$(aws iam list-open-id-connect-providers \
        --query "OpenIDConnectProviderList[?contains(Arn, '$CLUSTER_NAME')].Arn" \
        --output text \
        --region us-west-2 2>/dev/null || echo "")
    
    if [ ! -z "$oidc_arn" ]; then
        aws iam delete-open-id-connect-provider \
            --open-id-connect-provider-arn $oidc_arn \
            --region us-west-2
        log_success "OIDCèº«ä»½æä¾›ç¨‹åºåˆ é™¤å®Œæˆ"
    else
        log_info "æœªæ‰¾åˆ°ç›¸å…³çš„OIDCèº«ä»½æä¾›ç¨‹åº"
    fi
}

# æ£€æŸ¥é—ç•™èµ„æº
check_remaining_resources() {
    log_info "æ£€æŸ¥é—ç•™èµ„æº..."
    
    # æ£€æŸ¥EKSé›†ç¾¤
    if aws eks list-clusters --region us-west-2 | grep -q $CLUSTER_NAME; then
        log_warning "EKSé›†ç¾¤ä»ç„¶å­˜åœ¨"
    else
        log_success "EKSé›†ç¾¤å·²å®Œå…¨åˆ é™¤"
    fi
    
    # æ£€æŸ¥ECRä»“åº“
    local remaining_repos=$(aws ecr describe-repositories --region us-west-2 2>/dev/null | grep -c nacos-demo || echo "0")
    if [ "$remaining_repos" -eq 0 ]; then
        log_success "æ‰€æœ‰ECRä»“åº“å·²åˆ é™¤"
    else
        log_warning "ä»æœ‰ $remaining_repos ä¸ªECRä»“åº“å­˜åœ¨"
    fi
    
    # æ£€æŸ¥IAMè§’è‰²
    local remaining_roles=$(aws iam list-roles --query 'Roles[?contains(RoleName, `nacos`) || contains(RoleName, `EKSLoadBalancer`)].RoleName' --output text --region us-west-2 2>/dev/null || echo "")
    if [ -z "$remaining_roles" ]; then
        log_success "æ‰€æœ‰ç›¸å…³IAMè§’è‰²å·²åˆ é™¤"
    else
        log_warning "ä»æœ‰IAMè§’è‰²å­˜åœ¨: $remaining_roles"
    fi
    
    # æ£€æŸ¥è´Ÿè½½å‡è¡¡å™¨
    local remaining_albs=$(aws elbv2 describe-load-balancers \
        --query "LoadBalancers[?contains(LoadBalancerName, 'k8s-nacos')].LoadBalancerName" \
        --output text \
        --region us-west-2 2>/dev/null || echo "")
    if [ -z "$remaining_albs" ]; then
        log_success "æ‰€æœ‰ç›¸å…³è´Ÿè½½å‡è¡¡å™¨å·²åˆ é™¤"
    else
        log_warning "ä»æœ‰è´Ÿè½½å‡è¡¡å™¨å­˜åœ¨: $remaining_albs"
    fi
}

# æ¸…ç†æœ¬åœ°æ–‡ä»¶
cleanup_local_files() {
    log_info "æ¸…ç†æœ¬åœ°æ–‡ä»¶..."
    
    # æ¸…ç†Dockeré•œåƒ
    local nacos_images=$(docker images | grep nacos-demo | awk '{print $3}' 2>/dev/null || echo "")
    if [ ! -z "$nacos_images" ]; then
        echo "$nacos_images" | xargs docker rmi -f 2>/dev/null || true
        log_success "æœ¬åœ°Dockeré•œåƒæ¸…ç†å®Œæˆ"
    fi
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    rm -f iam_policy.json 2>/dev/null || true
    rm -rf ~/.kube/cache/discovery/$(aws sts get-caller-identity --query Account --output text).dkr.ecr.us-west-2.amazonaws.com_* 2>/dev/null || true
    
    log_success "æœ¬åœ°æ–‡ä»¶æ¸…ç†å®Œæˆ"
}

# ç”Ÿæˆåˆ é™¤æŠ¥å‘Š
generate_cleanup_report() {
    log_info "ç”Ÿæˆåˆ é™¤æŠ¥å‘Š..."
    
    local report_file="logs/cleanup-report-$(date +%Y%m%d-%H%M%S).txt"
    mkdir -p logs
    
    cat > $report_file << EOF
AWS us-west-2 èµ„æºåˆ é™¤æŠ¥å‘Š

åˆ é™¤æ—¶é—´: $(date)
AWSåŒºåŸŸ: us-west-2
é›†ç¾¤åç§°: $CLUSTER_NAME

å·²åˆ é™¤çš„èµ„æº:
- EKSé›†ç¾¤: $CLUSTER_NAME
- ECRä»“åº“: nacos-demo/gateway-service, nacos-demo/user-service, nacos-demo/order-service, nacos-demo/notification-service
- IAMè§’è‰²: nacos-eks-cluster-role, AmazonEKSLoadBalancerControllerRole
- IAMç­–ç•¥: AWSLoadBalancerControllerIAMPolicy
- Kubernetesèµ„æº: æ‰€æœ‰Podã€Serviceã€Ingressã€ConfigMapã€Secret
- è´Ÿè½½å‡è¡¡å™¨: ALB (é€šè¿‡Ingressåˆ é™¤)

é¢„è®¡èŠ‚çœè´¹ç”¨ï¼ˆæ¯å¤©ï¼‰:
- EKSé›†ç¾¤: \$0.10/å°æ—¶ Ã— 24 = \$2.40
- EC2å®žä¾‹: \$0.0416/å°æ—¶ Ã— 3 Ã— 24 = \$2.99
- ALB: \$0.0225/å°æ—¶ Ã— 24 = \$0.54
- æ€»è®¡çº¦: \$6-8/å¤©

æ³¨æ„äº‹é¡¹:
- è¯·åœ¨24å°æ—¶åŽæ£€æŸ¥AWSè´¦å•ç¡®è®¤èµ„æºå·²å®Œå…¨æ¸…ç†
- å¦‚æœ‰å¼‚å¸¸è´¹ç”¨ï¼Œè¯·è”ç³»AWSæ”¯æŒ
- æœ¬åœ°Dockeré•œåƒå’Œé…ç½®æ–‡ä»¶å·²æ¸…ç†

åˆ é™¤çŠ¶æ€: å®Œæˆ
EOF
    
    log_success "åˆ é™¤æŠ¥å‘Šå·²ç”Ÿæˆ: $report_file"
}

# è´¹ç”¨æé†’
cost_reminder() {
    log_info "è´¹ç”¨æé†’..."
    
    echo ""
    log_success "ðŸŽ‰ æ‰€æœ‰AWSèµ„æºåˆ é™¤å®Œæˆï¼"
    echo ""
    log_info "ðŸ’° é¢„è®¡èŠ‚çœè´¹ç”¨ï¼š"
    echo "   - EKSé›†ç¾¤: ~\$2.40/å¤©"
    echo "   - EC2å®žä¾‹: ~\$2.99/å¤©"
    echo "   - ALB: ~\$0.54/å¤©"
    echo "   - æ€»è®¡: ~\$6-8/å¤©"
    echo ""
    log_warning "â° é‡è¦æé†’ï¼š"
    echo "   - è¯·åœ¨24å°æ—¶åŽæ£€æŸ¥AWSè´¦å•"
    echo "   - ç¡®è®¤æ‰€æœ‰èµ„æºè´¹ç”¨å·²åœæ­¢"
    echo "   - å¦‚æœ‰å¼‚å¸¸ï¼Œè¯·è”ç³»AWSæ”¯æŒ"
    echo ""
}

# ä¸»å‡½æ•°
main() {
    log_info "å¼€å§‹AWSèµ„æºåˆ é™¤..."
    
    local start_time=$(date +%s)
    
    # ç¡®è®¤åˆ é™¤
    confirm_deletion
    
    # æ‰§è¡Œåˆ é™¤æ­¥éª¤
    delete_kubernetes_resources
    delete_alb_controller
    delete_eks_cluster
    delete_ecr_repositories
    delete_iam_resources
    delete_oidc_provider
    check_remaining_resources
    cleanup_local_files
    generate_cleanup_report
    cost_reminder
    
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    local minutes=$((duration / 60))
    local seconds=$((duration % 60))
    
    log_success "èµ„æºåˆ é™¤å®Œæˆï¼æ€»è€—æ—¶: ${minutes}åˆ†${seconds}ç§’"
}

# é”™è¯¯å¤„ç†
trap 'log_error "åˆ é™¤è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"; exit 1' ERR

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
